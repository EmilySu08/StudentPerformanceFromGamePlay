{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9c2d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "125a6510",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "trlabels = pd.read_csv(\"train_labels.csv\")\n",
    "trlabels = reduce_memory_usage(trlabels)\n",
    "sample = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec19772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trlabels['session'] = trlabels.session_id.apply(lambda s: int(s.split('_')[0]))\n",
    "trlabels['question'] = trlabels.session_id.apply(lambda s: int(s.split('_')[1][1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7f8e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train into 3 groups based on their levels\n",
    "df_0_4 = train[train['level_group'] == '0-4']\n",
    "df_0_4 = df_0_4[['level','session_id', 'index', 'elapsed_time', 'screen_coor_x']]\n",
    "\n",
    "df_5_12 = train[train['level_group'] == '5-12']\n",
    "df_5_12 = df_5_12[['level','session_id', 'index', 'elapsed_time', 'screen_coor_x']]\n",
    "\n",
    "df_13_22 = train[train['level_group'] == '13-22']\n",
    "df_13_22 = df_13_22[['level','session_id', 'index', 'elapsed_time', 'screen_coor_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35935481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def delt_time_def(df):\n",
    "#     df.sort_values(by=['session_id', 'elapsed_time'], inplace=True)\n",
    "#     df['delt_time'] = df['elapsed_time'].diff(1) # 对于同一个玩家的触发两个相邻的事件时的时间差\n",
    "#     df['delt_time'].fillna(0, inplace=True)\n",
    "#     df['delt_time'].clip(0, 103000, inplace=True) # 为什么是103000 s = 1716 min = 28 h\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d5962de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features \n",
    "CATS = ['event_name', 'name','fqid', 'room_fqid', 'text_fqid']\n",
    "\n",
    "# Numerical features\n",
    "NUMS = ['elapsed_time','level','page','room_coor_x', 'room_coor_y', \n",
    "        'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
    "\n",
    "# define the function to create the features\n",
    "def feature_engineer(train):\n",
    "    dfs = []\n",
    "    for c in CATS:\n",
    "        tmp = train.groupby(['session_id','level_group'])[c].agg('nunique')\n",
    "        tmp.name = tmp.name + '_nunique'\n",
    "        dfs.append(tmp)\n",
    "    for c in NUMS:\n",
    "        tmp = train.groupby(['session_id','level_group'])[c].agg('mean')\n",
    "        dfs.append(tmp)\n",
    "    for c in NUMS:\n",
    "        tmp = train.groupby(['session_id','level_group'])[c].agg('std')\n",
    "        tmp.name = tmp.name + '_std'\n",
    "        dfs.append(tmp)\n",
    "    df = pd.concat(dfs,axis=1)\n",
    "    df = df.fillna(-1)\n",
    "    df = df.reset_index()\n",
    "    df = df.set_index('session_id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a466db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will train with 21 features\n",
      "We will train with 23562 users info\n"
     ]
    }
   ],
   "source": [
    "new_train = feature_engineer(train)\n",
    "FEATURES = [c for c in new_train.columns if c != 'level_group'] # all features except the target\n",
    "print('We will train with', len(FEATURES) ,'features')\n",
    "ALL_USERS = new_train.index.unique() # treat each index as a user\n",
    "print('We will train with', len(ALL_USERS) ,'users info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b804eefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression()\n",
    "oof = pd.DataFrame(data=np.zeros((len(ALL_USERS),18)), index=ALL_USERS)\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13761558",
   "metadata": {},
   "outputs": [],
   "source": [
    " # ITERATE THRU QUESTIONS 1 THRU 18\n",
    "for t in range(1,19):\n",
    "        print(t,', ',end='')\n",
    "        \n",
    "        # USE THIS TRAIN DATA WITH THESE QUESTIONS\n",
    "        if t<=3: grp = '0-4'\n",
    "        elif t<=13: grp = '5-12'\n",
    "        elif t<=22: grp = '13-22'\n",
    "            \n",
    "        # TRAIN DATA\n",
    "        train_x = train.iloc[train_index]\n",
    "        train_x = train_x.loc[train_x.level_group == grp]\n",
    "        train_users = train_x.index.values\n",
    "        train_y = targets.loc[targets.q==t].set_index('session').loc[train_users]\n",
    "        \n",
    "        # VALID DATA\n",
    "        valid_x = train.iloc[test_index]\n",
    "        valid_x = valid_x.loc[valid_x.level_group == grp]\n",
    "        valid_users = valid_x.index.values\n",
    "        valid_y = targets.loc[targets.q==t].set_index('session').loc[valid_users]\n",
    "        \n",
    "        # TRAIN MODEL\n",
    "#         clf = CatBoostClassifier(n_estimators=500, depth=4, learning_rate=0.01, random_state=0) \n",
    "        clf.fit(train_x[FEATURES].astype('float32'), train_y['correct'])\n",
    "        \n",
    "        # SAVE MODEL, PREDICT VALID OOF\n",
    "        models[f'{grp}_{t}'] = clf\n",
    "#         oof.loc[valid_users, t-1] = clf.predict(valid_x[FEATURES].astype('float32'))[:,1]\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8ea79998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "#########################\n",
      "1 , "
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([       0,        1,        2,        3,        4,        6,\\n                   7,        8,        9,       10,\\n            ...\\n            26295599, 26295600, 26295601, 26295602, 26295604, 26295605,\\n            26295606, 26295607, 26295608, 26295609],\\n           dtype='int64', name='session', length=3583080)] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [85], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m train_x \u001b[38;5;241m=\u001b[39m train_x\u001b[38;5;241m.\u001b[39mloc[train_x\u001b[38;5;241m.\u001b[39mlevel_group \u001b[38;5;241m==\u001b[39m grp]\n\u001b[1;32m     24\u001b[0m train_users \u001b[38;5;241m=\u001b[39m train_x\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m---> 25\u001b[0m train_y \u001b[38;5;241m=\u001b[39m \u001b[43mtrlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msession\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_users\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# VALID DATA\u001b[39;00m\n\u001b[1;32m     28\u001b[0m valid_x \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39miloc[test_index]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1194\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1192\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1330\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1327\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1328\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1330\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:5796\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5794\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5796\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5798\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5800\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:5856\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5855\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5858\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5859\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([       0,        1,        2,        3,        4,        6,\\n                   7,        8,        9,       10,\\n            ...\\n            26295599, 26295600, 26295601, 26295602, 26295604, 26295605,\\n            26295606, 26295607, 26295608, 26295609],\\n           dtype='int64', name='session', length=3583080)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "gkf = GroupKFold(n_splits=10)\n",
    "oof = pd.DataFrame(data=np.zeros((len(ALL_USERS),18)), index=ALL_USERS)\n",
    "models = {}\n",
    "\n",
    "# COMPUTE CV SCORE WITH 5 GROUP K FOLD\n",
    "for i, (train_index, test_index) in enumerate(gkf.split(X=train, groups=train.index)):\n",
    "    print('#'*25)\n",
    "    print('### Fold',i+1)\n",
    "    print('#'*25)\n",
    "    \n",
    "    # ITERATE THRU QUESTIONS 1 THRU 18\n",
    "    for t in range(1,19):\n",
    "        print(t,', ',end='')\n",
    "        \n",
    "        # USE THIS TRAIN DATA WITH THESE QUESTIONS\n",
    "        if t<=3: grp = '0-4'\n",
    "        elif t<=13: grp = '5-12'\n",
    "        elif t<=22: grp = '13-22'\n",
    "            \n",
    "        # TRAIN DATA\n",
    "        train_x = train.iloc[train_index]\n",
    "        train_x = train_x.loc[train_x.level_group == grp]\n",
    "        train_users = train_x.index.values\n",
    "        train_y = trlabels.loc[trlabels.question==t].set_index('session').loc[train_users]\n",
    "        \n",
    "        # VALID DATA\n",
    "        valid_x = train.iloc[test_index]\n",
    "        valid_x = valid_x.loc[valid_x.level_group == grp]\n",
    "        valid_users = valid_x.index.values\n",
    "        valid_y = trlabels.loc[trlabels.question ==t].set_index('session').loc[valid_users]\n",
    "        \n",
    "        # TRAIN MODEL\n",
    "        clf = LinearRegression() \n",
    "        clf.fit(train_x[FEATURES].astype('float32'), train_y['correct'])\n",
    "        \n",
    "        # SAVE MODEL, PREDICT VALID OOF\n",
    "        models[f'{grp}_{t}'] = clf\n",
    "        oof.loc[valid_users, t-1] = clf.predict(valid_x[FEATURES].astype('float32'))[:,1]\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c29e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028ff0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5488a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train1 shape : (3981005, 5)\n",
      "train2 shape : (8844030, 5)\n",
      "train3 shape : (13123678, 5)\n"
     ]
    }
   ],
   "source": [
    "kol_lvl = (df_0_4.groupby(['session_id'])['level'].agg('nunique') < 5) \n",
    "# 统计每组的level中的值的种类数量，将种类数小于5的组标记为True，也就是只要level数小于5说明这一阶段的都没有通关\n",
    "# print(kol_lvl.shape)\n",
    "# print(kol_lvl)\n",
    "list_session = kol_lvl[kol_lvl].index  \n",
    "# 又因为kol_lvl的行索引就是session_id，因此直接将筛选的布尔矩阵的放进kol_lvl就可以，选择正确的id\n",
    "# print(kol_lvl[kol_lvl])\n",
    "df_0_4 = df_0_4[~ df_0_4['session_id'].isin(list_session) ] \n",
    "# session_id的值不在这个list_session就为False，否则为True，然后取反：获得符合要求的id\n",
    "\n",
    "# df_0_4 = delt_time_def(df_0_4)\n",
    "train1 = df_0_4\n",
    "\n",
    "print(f\"train1 shape : {train1.shape}\")\n",
    "\n",
    "kol_lvl = (df_5_12.groupby(['session_id'])['level'].agg('nunique') < 8) # 小于8个的id没有通关，不要\n",
    "list_session = kol_lvl[kol_lvl].index  # index返回的是不符合要求的session_id，因为行索引就是session_id\n",
    "\n",
    "df_5_12 = df_5_12[~df_5_12['session_id'].isin(list_session)] # 如果某一列是不正确的id，则取反变成False不选择这一行\n",
    "\n",
    "# df_5_12 = delt_time_def(df_5_12)\n",
    "train2 = df_5_12\n",
    "\n",
    "print(f\"train2 shape : {train2.shape}\")\n",
    "\n",
    "kol_lvl = (df_13_22.groupby(['session_id'])['level'].agg('nunique') < 10) # 小于10个的id没有通关，不要\n",
    "list_session = kol_lvl[kol_lvl].index\n",
    "df_13_22 = df_13_22[~ df_13_22['session_id'].isin(list_session) ]\n",
    "\n",
    "# df_13_22 = delt_time_def(df_13_22)\n",
    "train3 = df_13_22\n",
    "\n",
    "print(f\"train3 shape : {train3.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f023b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will train with 5 5 5 features\n",
      "We will train with 3981005 users info\n"
     ]
    }
   ],
   "source": [
    "FEATURES1 = [c for c in train1.columns if c not in ['level_group']] # 由于这里只有NUM类型的数据因此每个level的\n",
    "FEATURES2 = [c for c in train2.columns if c not in ['level_group']]\n",
    "FEATURES3 = [c for c in train3.columns if c not in ['level_group']]\n",
    "print('We will train with', len(FEATURES1), len(FEATURES2), len(FEATURES3) ,'features')\n",
    "ALL_USERS = train1.index.unique()\n",
    "print('We will train with', len(ALL_USERS) ,'users info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a84d2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_params = {\n",
    "#     'objective' : 'binary:logistic',\n",
    "#     'eval_metric':'logloss',\n",
    "#     'learning_rate': 0.05,\n",
    "#     'max_depth': 4,\n",
    "#     'n_estimators': 1000,\n",
    "#     'early_stopping_rounds': 50,\n",
    "#     'tree_method':'hist',\n",
    "#     'subsample':0.8,\n",
    "#     'colsample_bytree': 0.4,\n",
    "#     'use_label_encoder' : False}\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1621da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(1,19):\n",
    "    # 分别训练不同问题的分类器\n",
    "    if t <= 3:\n",
    "        grp = '0-4'\n",
    "        df = train1.fillna(-1)\n",
    "        FEATURES = FEATURES1\n",
    "        \n",
    "    elif t <= 13:\n",
    "        grp = '5-12'\n",
    "        df = train2.fillna(-1)\n",
    "        FEATURES = FEATURES2\n",
    "    \n",
    "    elif t <= 22:\n",
    "        grp = '13-22'\n",
    "        df = train3.fillna(-1)\n",
    "        FEATURES = FEATURES3\n",
    "    \n",
    "    # TRAIN DATA\n",
    "    train_x = df\n",
    "#     print(train_x.shape, end=',')\n",
    "    train_users = train_x.index.values # 返回train数据集中存在的session_id的列表\n",
    "    #print(train_users)\n",
    "    print(trlabels.loc[trlabels['question'] == t].set_index('session').loc[train_users])\n",
    "    print()\n",
    "    print(trlabels.loc[trlabels['question'] == t].set_index('session'))\n",
    "#     print()\n",
    "#     print(trlabels.loc[trlabels['question'] == t].set_index('session').loc[0])\n",
    "#     print(train_users, end)\n",
    "    #train_y = trlabels.loc[trlabels['question'] == t].set_index('session').loc[train_users] # 选择第t个问题的标签且id在训练数据中的\n",
    "    #train_y = train_y['correct']\n",
    "#     print(train_y.shape)\n",
    "\n",
    "# #     print(\"Xtrain\")\n",
    "# #     print(X_train[FEATURES])\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(train_x[['l_ev_name_observation_click','t_ev_name_observation_click']], train_y, test_size=0.2)\n",
    "#     clf = LinearRegression()\n",
    "#     clf.fit(X_train.astype('float32'), y_train)\n",
    "    \n",
    "# #     print(X_train[['l_ev_name_observation_click','t_ev_name_observation_click']])\n",
    "# #     print(f'quiz{t}, train data shape is {X_train[FEATURES].shape}, test data shape is {y_train.shape}')\n",
    "#     print(\"train data F1 score is \", f1_score(y_train, clf.predict(X_train)))\n",
    "# #     print(f'test data F1 score is ', f1_score(y_test, clf.predict(X_test)))\n",
    "#     # SAVE MODEL, PREDICT VALID OOF\n",
    "#     models[f'{grp}_{t}'] = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e06aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trlabels['session_id'].values)\n",
    "print(trlabels['Question'].values)\n",
    "\n",
    "# print(trlabels['IDQ'].iloc[i].index('_'))\n",
    "#separate session ids into question groups (1-18)\n",
    "#merge train w/ train_labels to get correct column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge trlabels and train to get Y (correct) and then predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f6d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = trlabels.groupby('Question').get_group('q1')\n",
    "\n",
    "IDs = trlabels.groupby('Question').get_group('q1')['session_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd62fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = train[~train['session_id'].isin(IDs)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd553618",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = g1.groupby('level_group').get_group('0-4')\n",
    "# print(len(g1['session_id']))\n",
    "\n",
    "# print(len(group1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304fdd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train and test data \n",
    "X = g1\n",
    "Y = group1\n",
    "print(len(X))\n",
    "print(len(Y))\n",
    "# train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.4, random_state = 213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct models\n",
    "#print(X)\n",
    "reg = LinearRegression().fit(train_x, (train_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model on test \n",
    "Xtest = test[['session_id', 'music']]\n",
    "\n",
    "print(np.unique(reg.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923cfbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy variables "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
